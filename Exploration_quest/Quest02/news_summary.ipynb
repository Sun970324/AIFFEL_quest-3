{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 기본 embedding, LSTM"
      ],
      "metadata": {
        "id": "PytesyA06oPk"
      },
      "id": "PytesyA06oPk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13cf0dfb"
      },
      "source": [
        "## 데이터 증강 text attack"
      ],
      "id": "13cf0dfb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8450ea6",
        "outputId": "e30372d6-66c5-47b8-b359-f6ce69e9b3e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.6.5\n",
            "2.6.0\n",
            "1.3.3\n",
            "1.2.0\n"
          ]
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "import nltk\n",
        "import tensorflow\n",
        "import summa\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from bs4 import BeautifulSoup\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import urllib.request\n",
        "\n",
        "print(nltk.__version__)\n",
        "print(tensorflow.__version__)\n",
        "print(pd.__version__)\n",
        "print(version('summa'))"
      ],
      "id": "d8450ea6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "de3736ff",
        "outputId": "5b0a33ea-283f-40f4-ff5c-0f0b34dfda61"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords"
      ],
      "id": "de3736ff"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccc29002"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')"
      ],
      "id": "ccc29002"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "848ab9f2"
      },
      "source": [
        "## 데이터전처리"
      ],
      "id": "848ab9f2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "988309d7"
      },
      "outputs": [],
      "source": [
        "# import urllib.request\n",
        "# urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
        "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
      ],
      "id": "988309d7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06c0aa10"
      },
      "outputs": [],
      "source": [
        "data.loc[0].text"
      ],
      "id": "06c0aa10"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efe57487"
      },
      "outputs": [],
      "source": [
        "data.loc[0].headlines"
      ],
      "id": "efe57487"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1ecab2a"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ],
      "id": "c1ecab2a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ba06ea33"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ],
      "id": "ba06ea33"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed29eb4d"
      },
      "source": [
        "### 중복, null값 제거"
      ],
      "id": "ed29eb4d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dce7b64a"
      },
      "outputs": [],
      "source": [
        "# 중복값 제거\n",
        "print('text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())\n",
        "print('headlines 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())"
      ],
      "id": "dce7b64a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5840d349"
      },
      "outputs": [],
      "source": [
        "# inplace=True 를 설정하면 DataFrame 내부를 직접적으로 바꿈\n",
        "data.drop_duplicates(subset = ['text'], inplace=True)\n",
        "data.drop_duplicates(subset = ['headlines'], inplace=True)\n",
        "print('전체 샘플수 :', (len(data)))\n",
        "# 중복값 제거\n",
        "print('text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())\n",
        "print('headlines 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())"
      ],
      "id": "5840d349"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "078cde6d"
      },
      "outputs": [],
      "source": [
        "# null값 있는지 확인\n",
        "print(data.isnull().sum())"
      ],
      "id": "078cde6d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "640993e4"
      },
      "source": [
        "### 텍스트 정규화와 불용어 제거"
      ],
      "id": "640993e4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68f3e5c8"
      },
      "outputs": [],
      "source": [
        "# 정규화 사전구성\n",
        "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "id": "68f3e5c8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4009336a"
      },
      "outputs": [],
      "source": [
        "print('불용어 개수 :', len(stopwords.words('english') ))\n",
        "print(stopwords.words('english'))"
      ],
      "id": "4009336a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf2fbac4"
      },
      "outputs": [],
      "source": [
        "# 데이터 전처리 함수\n",
        "def preprocess_sentence(sentence, remove_stopwords=True):\n",
        "    sentence = sentence.lower() # 텍스트 소문자화\n",
        "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
        "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
        "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
        "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
        "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
        "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
        "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
        "\n",
        "    # 불용어 제거 (Text)\n",
        "    if remove_stopwords:\n",
        "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
        "    # 불용어 미제거 (Summary)\n",
        "    else:\n",
        "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
        "    return tokens"
      ],
      "id": "cf2fbac4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1d1fd936"
      },
      "outputs": [],
      "source": [
        "clean_text = []\n",
        "\n",
        "for sentence in data['text']:\n",
        "    cleaned = preprocess_sentence(sentence)\n",
        "    clean_text.append(cleaned)\n",
        "\n",
        "# 전처리 후 출력\n",
        "print(\"Text 전처리 후 결과: \", clean_text[:5])"
      ],
      "id": "1d1fd936"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c305fd32"
      },
      "outputs": [],
      "source": [
        "clean_headlines = []\n",
        "\n",
        "for sentence in data['headlines']:\n",
        "    cleaned = preprocess_sentence(sentence,False)\n",
        "    clean_headlines.append(cleaned)\n",
        "\n",
        "print(\"Summary 전처리 후 결과: \", clean_headlines[:5])"
      ],
      "id": "c305fd32"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ec8e61a7"
      },
      "outputs": [],
      "source": [
        "data['text'] = clean_text\n",
        "data['headlines'] = clean_headlines"
      ],
      "id": "ec8e61a7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dbc2433"
      },
      "outputs": [],
      "source": [
        "# null값 생겼는지 확인\n",
        "data.isnull().sum()"
      ],
      "id": "6dbc2433"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ed5d96f5"
      },
      "outputs": [],
      "source": [
        "data.to_csv('news_data.csv', index=False)"
      ],
      "id": "ed5d96f5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2199f3e"
      },
      "source": [
        "## 데이터 전처리, 불용어 제거 후"
      ],
      "id": "a2199f3e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98a08145"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('news_data.csv')"
      ],
      "id": "98a08145"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ca458646"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ],
      "id": "ca458646"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23407f82"
      },
      "outputs": [],
      "source": [
        "# 길이 분포 출력\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "text_len = [len(s.split()) for s in data['text']]\n",
        "headlines_len = [len(s.split()) for s in data['headlines']]\n",
        "\n",
        "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
        "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
        "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
        "print('헤드라인의 최소 길이 : {}'.format(np.min(headlines_len)))\n",
        "print('헤드라인의 최대 길이 : {}'.format(np.max(headlines_len)))\n",
        "print('헤드라인의 평균 길이 : {}'.format(np.mean(headlines_len)))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.boxplot(text_len)\n",
        "plt.title('Text')\n",
        "plt.subplot(1,2,2)\n",
        "plt.boxplot(headlines_len)\n",
        "plt.title('Headline')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.title('Text')\n",
        "plt.hist(text_len, bins = 40)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()\n",
        "\n",
        "plt.title('Headlines')\n",
        "plt.hist(headlines_len, bins = 40)\n",
        "plt.xlabel('length of Headlines')\n",
        "plt.ylabel('number of Headlines')\n",
        "plt.show()"
      ],
      "id": "23407f82"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7e2070d"
      },
      "outputs": [],
      "source": [
        "# data['text_len'] = text_len\n",
        "# data['text_head'] = headlines_len"
      ],
      "id": "b7e2070d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ed346e95"
      },
      "outputs": [],
      "source": [
        "# data_text = data.sort_values(by='text_len')"
      ],
      "id": "ed346e95"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7b120028"
      },
      "outputs": [],
      "source": [
        "# data_text"
      ],
      "id": "7b120028"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58584d19"
      },
      "outputs": [],
      "source": [
        "# data_head = data.sort_values(by='text_head')"
      ],
      "id": "58584d19"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53cef139"
      },
      "outputs": [],
      "source": [
        "# data_head"
      ],
      "id": "53cef139"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "574e4724"
      },
      "source": [
        "index 52 : 제목이 추가돼버려서 삭제  "
      ],
      "id": "574e4724"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9630472"
      },
      "outputs": [],
      "source": [
        "data = data.drop(52)"
      ],
      "id": "d9630472"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9d2a6506"
      },
      "outputs": [],
      "source": [
        "# 길이 분포 출력\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "text_len = [len(s.split()) for s in data['text']]\n",
        "headlines_len = [len(s.split()) for s in data['headlines']]\n",
        "\n",
        "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
        "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
        "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
        "print('헤드라인의 최소 길이 : {}'.format(np.min(headlines_len)))\n",
        "print('헤드라인의 최대 길이 : {}'.format(np.max(headlines_len)))\n",
        "print('헤드라인의 평균 길이 : {}'.format(np.mean(headlines_len)))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.boxplot(text_len)\n",
        "plt.title('Text')\n",
        "plt.subplot(1,2,2)\n",
        "plt.boxplot(headlines_len)\n",
        "plt.title('Headline')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.title('Text')\n",
        "plt.hist(text_len, bins = 40)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()\n",
        "\n",
        "plt.title('Headlines')\n",
        "plt.hist(headlines_len, bins = 40)\n",
        "plt.xlabel('length of Headlines')\n",
        "plt.ylabel('number of Headlines')\n",
        "plt.show()"
      ],
      "id": "9d2a6506"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4abafedb"
      },
      "source": [
        "### 시작, 종료 토큰 추가하기"
      ],
      "id": "4abafedb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab24d0ab"
      },
      "outputs": [],
      "source": [
        "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostoken '+ x)\n",
        "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
        "data.head()"
      ],
      "id": "ab24d0ab"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "456d004c"
      },
      "outputs": [],
      "source": [
        "data.to_csv('data_input.csv',index=False)"
      ],
      "id": "456d004c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92cb1435"
      },
      "source": [
        "## 최종 데이터"
      ],
      "id": "92cb1435"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f040e201"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('data_input.csv')"
      ],
      "id": "f040e201"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e52767ca"
      },
      "outputs": [],
      "source": [
        "# 인코더의 입력, 디코더의 입력과 레이블을 각각 다시 Numpy 타입으로 저장\n",
        "encoder_input = np.array(data['text']) # 인코더의 입력\n",
        "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
        "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
      ],
      "id": "e52767ca"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "476816f2",
        "outputId": "c1fa2c09-de75-4f37-8817-48307a49ee69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[78891 68140 45937 ... 79517 28718  8226]\n"
          ]
        }
      ],
      "source": [
        "# encoder_input과 크기와 형태가 같은 순서가 섞인 정수 시퀀스를 만들기\n",
        "indices = np.arange(encoder_input.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "print(indices)"
      ],
      "id": "476816f2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f18e0f3"
      },
      "source": [
        "### train, test data 분리하기"
      ],
      "id": "3f18e0f3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cd028ad"
      },
      "outputs": [],
      "source": [
        "# shuffle된 indices 시퀀스를 이용해 잘 섞인 샘플 만들기\n",
        "encoder_input = encoder_input[indices]\n",
        "decoder_input = decoder_input[indices]\n",
        "decoder_target = decoder_target[indices]\n",
        "\n",
        "# 섞인 데이터를 8:2의 비율로 훈련 데이터와 테스트 데이터로 분리\n",
        "# 텍스트 데이터 갯수 정하기\n",
        "n_of_val = int(len(encoder_input)*0.2)\n",
        "\n",
        "# 데이터 나누기\n",
        "encoder_input_train = encoder_input[:-n_of_val]\n",
        "decoder_input_train = decoder_input[:-n_of_val]\n",
        "decoder_target_train = decoder_target[:-n_of_val]\n",
        "\n",
        "encoder_input_test = encoder_input[-n_of_val:]\n",
        "decoder_input_test = decoder_input[-n_of_val:]\n",
        "decoder_target_test = decoder_target[-n_of_val:]"
      ],
      "id": "8cd028ad"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b803191"
      },
      "source": [
        "### 단어집합 만들고 정수인코딩 하기"
      ],
      "id": "2b803191"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1549a8d1"
      },
      "outputs": [],
      "source": [
        "# Keras의 토크나이저를 사용해서 입력된 훈련 데이터로부터 단어 집합을 만들기\n",
        "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
        "src_tokenizer.fit_on_texts(encoder_input_train) # 리스트를 인자로 받고 숫자정보를 매핑"
      ],
      "id": "1549a8d1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4c39b921",
        "outputId": "7ecebb99-4d45-48ec-9aa3-29d5d81eb8f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "단어 집합 : 69531\n"
          ]
        }
      ],
      "source": [
        "src_vocab_size = len(src_tokenizer.word_index) + 1 # 패딩을 고려하여 +1\n",
        "print('단어 집합 :',src_vocab_size)"
      ],
      "id": "4c39b921"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12db2083",
        "outputId": "179f8b21-4c4f-4a1e-88ed-bebc26816c10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "단어 집합(vocabulary)의 크기 : 69530\n",
            "등장 빈도가 6번 이하인 희귀 단어의 수: 47383\n",
            "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 22147\n",
            "단어 집합에서 희귀 단어의 비율: 68.14756220336545\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.489958519395725\n"
          ]
        }
      ],
      "source": [
        "# 등장 빈도수가 7회 미만인 단어들이 이 데이터에서 얼만큼의 비중을 차지하는지 확인\n",
        "threshold = 7\n",
        "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
        "\n",
        "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
        "for key, value in src_tokenizer.word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if(value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
        "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ],
      "id": "12db2083"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c3e1512"
      },
      "source": [
        "20000으로 단어집합의 크기를 제한"
      ],
      "id": "1c3e1512"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b00f7c3e"
      },
      "outputs": [],
      "source": [
        "src_vocab = 20000\n",
        "src_tokenizer = Tokenizer(num_words=src_vocab)\n",
        "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성"
      ],
      "id": "b00f7c3e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "703ad291",
        "outputId": "2bea05db-5d18-407f-f8ae-d93b902ea949"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[5861, 3593, 202, 7572, 293, 5916, 6739, 364, 1085, 293, 137, 2516, 4339, 3416, 2516, 6989, 11257, 2516, 146, 160, 708, 4369, 909, 5916, 5861, 542, 1010, 16701, 1854, 7, 378], [5, 16, 125, 44, 72, 66, 427, 1586, 10702, 5641, 5917, 3795, 3263, 1081, 1002, 771, 5, 84, 2799, 424, 12564, 244, 63, 376, 861, 158, 260, 575, 469, 44, 1655, 469, 2799, 2025, 2517, 5114, 10056], [1446, 109, 360, 94, 9, 1362, 78, 79, 1521, 174, 95, 391, 1446, 9, 6, 184, 8822, 1487, 110, 265, 1521, 241, 22, 2728, 15372, 1446, 9, 2477, 500, 3019, 207]]\n"
          ]
        }
      ],
      "source": [
        "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
        "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train)\n",
        "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
        "\n",
        "# 잘 진행되었는지 샘플 출력\n",
        "print(encoder_input_train[:3])"
      ],
      "id": "703ad291"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5533a3c5"
      },
      "outputs": [],
      "source": [
        "tar_tokenizer = Tokenizer()\n",
        "tar_tokenizer.fit_on_texts(decoder_input_train)"
      ],
      "id": "5533a3c5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7597abb",
        "outputId": "120f0807-ce6f-4a22-d306-6597354e723f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "단어 집합 : 30003\n"
          ]
        }
      ],
      "source": [
        "tar_vocab_size = len(tar_tokenizer.word_index) + 1 # 패딩을 고려하여 +1\n",
        "print('단어 집합 :',tar_vocab_size)"
      ],
      "id": "a7597abb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94e388bf",
        "outputId": "c32e8654-1b1e-49e7-f648-87d58bda82b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "단어 집합(vocabulary)의 크기 : 30002\n",
            "등장 빈도가 5번 이하인 희귀 단어의 수: 19572\n",
            "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 10430\n",
            "단어 집합에서 희귀 단어의 비율: 65.2356509566029\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 4.6227111024889815\n"
          ]
        }
      ],
      "source": [
        "threshold = 6\n",
        "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
        "\n",
        "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
        "for key, value in tar_tokenizer.word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if(value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
        "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ],
      "id": "94e388bf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cf9285f"
      },
      "source": [
        "단어집합 10000개로 제한"
      ],
      "id": "2cf9285f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ae71536a"
      },
      "outputs": [],
      "source": [
        "tar_vocab = 10000\n",
        "tar_tokenizer = Tokenizer(num_words=tar_vocab)\n",
        "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
        "tar_tokenizer.fit_on_texts(decoder_target_train)"
      ],
      "id": "ae71536a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "106a9a77",
        "outputId": "a8f053e6-b37c-4908-c6b9-95925f1dd72f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input\n",
            "input  [[1, 50, 314, 3489, 19, 50, 4, 189, 2683, 4541, 3490, 3238], [1, 29, 185, 74, 6, 2230, 13, 331, 1673], [1, 1349, 61, 1542, 744, 104, 65, 393, 153, 3, 201], [1, 154, 149, 1350, 1951, 15, 174, 157, 6, 30, 1018], [1, 63, 26, 2106, 146, 499, 153, 5, 1112, 5634]]\n",
            "target\n",
            "decoder  [[50, 314, 3489, 19, 50, 4, 189, 2683, 4541, 3490, 3238, 2], [29, 185, 74, 6, 2230, 13, 331, 1673, 2], [1349, 61, 1542, 744, 104, 65, 393, 153, 3, 201, 2], [154, 149, 1350, 1951, 15, 174, 157, 6, 30, 1018, 2], [63, 26, 2106, 146, 499, 153, 5, 1112, 5634, 2]]\n"
          ]
        }
      ],
      "source": [
        "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
        "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train)\n",
        "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
        "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
        "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
        "\n",
        "# 잘 변환되었는지 확인\n",
        "print('input')\n",
        "print('input ',decoder_input_train[:5])\n",
        "print('target')\n",
        "print('decoder ',decoder_target_train[:5])"
      ],
      "id": "106a9a77"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2054fb29",
        "outputId": "7a3b5b8a-9989-4f6a-b073-f4c7e662c927"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "삭제할 훈련 데이터의 개수 : 0\n",
            "삭제할 테스트 데이터의 개수 : 0\n",
            "훈련 데이터의 개수 : 78609\n",
            "훈련 레이블의 개수 : 78609\n",
            "테스트 데이터의 개수 : 19652\n",
            "테스트 레이블의 개수 : 19652\n"
          ]
        }
      ],
      "source": [
        "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
        "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
        "\n",
        "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
        "print('삭제할 테스트 데이터의 개수 :', len(drop_test))\n",
        "\n",
        "encoder_input_train = [sentence for index, sentence in enumerate(encoder_input_train) if index not in drop_train]\n",
        "decoder_input_train = [sentence for index, sentence in enumerate(decoder_input_train) if index not in drop_train]\n",
        "decoder_target_train = [sentence for index, sentence in enumerate(decoder_target_train) if index not in drop_train]\n",
        "\n",
        "encoder_input_test = [sentence for index, sentence in enumerate(encoder_input_test) if index not in drop_test]\n",
        "decoder_input_test = [sentence for index, sentence in enumerate(decoder_input_test) if index not in drop_test]\n",
        "decoder_target_test = [sentence for index, sentence in enumerate(decoder_target_test) if index not in drop_test]\n",
        "\n",
        "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
        "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
        "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
        "print('테스트 레이블의 개수 :', len(decoder_input_test))"
      ],
      "id": "2054fb29"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "240658e3"
      },
      "source": [
        "### 패딩하기"
      ],
      "id": "240658e3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2669ba1"
      },
      "outputs": [],
      "source": [
        "text_max_len = 60\n",
        "head_max_len = 16\n",
        "\n",
        "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
        "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
        "decoder_input_train = pad_sequences(decoder_input_train, maxlen=head_max_len, padding='post')\n",
        "decoder_target_train = pad_sequences(decoder_target_train, maxlen=head_max_len, padding='post')\n",
        "decoder_input_test = pad_sequences(decoder_input_test, maxlen=head_max_len, padding='post')\n",
        "decoder_target_test = pad_sequences(decoder_target_test, maxlen=head_max_len, padding='post')"
      ],
      "id": "a2669ba1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "450970a2"
      },
      "source": [
        "## 모델 설계하기"
      ],
      "id": "450970a2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8274ac2"
      },
      "source": [
        "### LSTM"
      ],
      "id": "c8274ac2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3356d230"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# 인코더 설계 시작\n",
        "embedding_dim = 128\n",
        "hidden_size = 256\n",
        "\n",
        "# 인코더\n",
        "encoder_inputs = Input(shape=(text_max_len,))\n",
        "\n",
        "# 인코더의 임베딩 층\n",
        "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
        "\n",
        "# 인코더의 LSTM 1\n",
        "# encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
        "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "# 인코더의 LSTM 2\n",
        "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "# 인코더의 LSTM 3\n",
        "encoder_lstm3 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm3(encoder_output2)"
      ],
      "id": "3356d230"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c12364ee"
      },
      "outputs": [],
      "source": [
        "# 디코더 설계\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "# 디코더의 임베딩 층\n",
        "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# 디코더의 LSTM\n",
        "# decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
        "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])"
      ],
      "id": "c12364ee"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f38e4b0"
      },
      "source": [
        "### Attention layer 추가"
      ],
      "id": "4f38e4b0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1055d1b7",
        "outputId": "9f043751-69e5-47e4-afbc-f91502ad1e69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 60)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 60, 128)      2560000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 60, 256), (N 394240      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 60, 256), (N 525312      lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 128)    1280000     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 60, 256), (N 525312      lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AdditiveAttent (None, None, 256)    256         lstm_3[0][0]                     \n",
            "                                                                 lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 10000)  5130000     concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 10,809,360\n",
            "Trainable params: 10,809,360\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import AdditiveAttention\n",
        "\n",
        "# 어텐션 층(어텐션 함수)\n",
        "attn_layer = AdditiveAttention(name='attention_layer')\n",
        "\n",
        "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
        "attn_out = attn_layer([decoder_outputs, encoder_outputs])\n",
        "\n",
        "\n",
        "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "# 디코더의 출력층\n",
        "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
        "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
        "\n",
        "# 모델 정의\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
        "model.summary()"
      ],
      "id": "1055d1b7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24d13003"
      },
      "source": [
        "### 모델 훈련하기"
      ],
      "id": "24d13003"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cd7e3c6d",
        "outputId": "baa1e38d-b2f1-4075-a2b0-fcde2cdf3305"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "308/308 [==============================] - 47s 129ms/step - loss: 4.2846 - val_loss: 3.9448\n",
            "Epoch 2/50\n",
            "308/308 [==============================] - 40s 130ms/step - loss: 3.7901 - val_loss: 3.6556\n",
            "Epoch 3/50\n",
            "308/308 [==============================] - 41s 135ms/step - loss: 3.5482 - val_loss: 3.5067\n",
            "Epoch 4/50\n",
            "293/308 [===========================>..] - ETA: 1s - loss: 3.3644"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
        "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
        "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
        "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
        "          batch_size=256, callbacks=[es], epochs=50)"
      ],
      "id": "cd7e3c6d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "313e5bd8"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='val')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "313e5bd8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c439725"
      },
      "source": [
        "### 인퍼런스 모델 구현하기"
      ],
      "id": "5c439725"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ac36ffc"
      },
      "outputs": [],
      "source": [
        "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
        "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
        "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음"
      ],
      "id": "1ac36ffc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eeb0754"
      },
      "outputs": [],
      "source": [
        "# 인코더 설계\n",
        "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# 이전 시점의 상태들을 저장하는 텐서\n",
        "decoder_state_input_h = Input(shape=(hidden_size,))\n",
        "decoder_state_input_c = Input(shape=(hidden_size,))\n",
        "\n",
        "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
        "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])"
      ],
      "id": "4eeb0754"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d969d4bd"
      },
      "outputs": [],
      "source": [
        "# 어텐션 함수\n",
        "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
        "attn_out_inf = attn_layer([decoder_outputs2, decoder_hidden_state_input])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# 디코더의 출력층\n",
        "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat)\n",
        "\n",
        "# 최종 디코더 모델\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])"
      ],
      "id": "d969d4bd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bafa9e2"
      },
      "outputs": [],
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # 입력으로부터 인코더의 상태를 얻음\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "\n",
        "     # <SOS>에 해당하는 토큰 생성\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
        "\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = tar_index_to_word[sampled_token_index]\n",
        "\n",
        "        if (sampled_token!='eostoken'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
        "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (head_max_len-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # 상태를 업데이트 합니다.\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "id": "2bafa9e2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b8a1f99"
      },
      "source": [
        "## 모델 테스트하기"
      ],
      "id": "8b8a1f99"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9440793"
      },
      "outputs": [],
      "source": [
        "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq2text(input_seq):\n",
        "    temp=''\n",
        "    for i in input_seq:\n",
        "        if (i!=0):\n",
        "            temp = temp + src_index_to_word[i]+' '\n",
        "    return temp\n",
        "\n",
        "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq2summary(input_seq):\n",
        "    temp=''\n",
        "    for i in input_seq:\n",
        "        if (i!=0 and i!=tar_word_to_index['sostoken'] and i!=tar_word_to_index['eostoken']):\n",
        "            temp = temp + tar_index_to_word[i]+' '\n",
        "    return temp.strip()"
      ],
      "id": "c9440793"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "375d832e"
      },
      "outputs": [],
      "source": [
        "for i in range(50, 100):\n",
        "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
        "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
        "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
        "    print(\"\\n\")"
      ],
      "id": "375d832e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Glove embedding + LSTM"
      ],
      "metadata": {
        "id": "eH1rcAun6_Qe"
      },
      "id": "eH1rcAun6_Qe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6ce9aab",
        "outputId": "04a8d687-3f96-465a-8f79-3a8824958fff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.6.5\n",
            "2.6.0\n",
            "1.3.3\n",
            "1.2.0\n"
          ]
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "import nltk\n",
        "import tensorflow\n",
        "import summa\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from bs4 import BeautifulSoup\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import urllib.request\n",
        "\n",
        "print(nltk.__version__)\n",
        "print(tensorflow.__version__)\n",
        "print(pd.__version__)\n",
        "print(version('summa'))"
      ],
      "id": "a6ce9aab"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "de3b33dc"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')"
      ],
      "id": "de3b33dc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8a8fc83"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('data_input.csv')"
      ],
      "id": "c8a8fc83"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c730bb3b",
        "outputId": "a250003f-bba8-4f39-f7d4-9c97e2e6beef"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headlines</th>\n",
              "      <th>text</th>\n",
              "      <th>decoder_input</th>\n",
              "      <th>decoder_target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>upgrad learner switches to career in ml al wit...</td>\n",
              "      <td>saurav kant alumnus upgrad iiit pg program mac...</td>\n",
              "      <td>sostoken upgrad learner switches to career in ...</td>\n",
              "      <td>upgrad learner switches to career in ml al wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>delhi techie wins free food from swiggy for on...</td>\n",
              "      <td>kunal shah credit card bill payment platform c...</td>\n",
              "      <td>sostoken delhi techie wins free food from swig...</td>\n",
              "      <td>delhi techie wins free food from swiggy for on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>new zealand end rohit sharma led india match w...</td>\n",
              "      <td>new zealand defeated india wickets fourth odi ...</td>\n",
              "      <td>sostoken new zealand end rohit sharma led indi...</td>\n",
              "      <td>new zealand end rohit sharma led india match w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>aegon life iterm insurance plan helps customer...</td>\n",
              "      <td>aegon life iterm insurance plan customers enjo...</td>\n",
              "      <td>sostoken aegon life iterm insurance plan helps...</td>\n",
              "      <td>aegon life iterm insurance plan helps customer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>have known hirani for yrs what if metoo claims...</td>\n",
              "      <td>speaking sexual harassment allegations rajkuma...</td>\n",
              "      <td>sostoken have known hirani for yrs what if met...</td>\n",
              "      <td>have known hirani for yrs what if metoo claims...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           headlines  \\\n",
              "0  upgrad learner switches to career in ml al wit...   \n",
              "1  delhi techie wins free food from swiggy for on...   \n",
              "2  new zealand end rohit sharma led india match w...   \n",
              "3  aegon life iterm insurance plan helps customer...   \n",
              "4  have known hirani for yrs what if metoo claims...   \n",
              "\n",
              "                                                text  \\\n",
              "0  saurav kant alumnus upgrad iiit pg program mac...   \n",
              "1  kunal shah credit card bill payment platform c...   \n",
              "2  new zealand defeated india wickets fourth odi ...   \n",
              "3  aegon life iterm insurance plan customers enjo...   \n",
              "4  speaking sexual harassment allegations rajkuma...   \n",
              "\n",
              "                                       decoder_input  \\\n",
              "0  sostoken upgrad learner switches to career in ...   \n",
              "1  sostoken delhi techie wins free food from swig...   \n",
              "2  sostoken new zealand end rohit sharma led indi...   \n",
              "3  sostoken aegon life iterm insurance plan helps...   \n",
              "4  sostoken have known hirani for yrs what if met...   \n",
              "\n",
              "                                      decoder_target  \n",
              "0  upgrad learner switches to career in ml al wit...  \n",
              "1  delhi techie wins free food from swiggy for on...  \n",
              "2  new zealand end rohit sharma led india match w...  \n",
              "3  aegon life iterm insurance plan helps customer...  \n",
              "4  have known hirani for yrs what if metoo claims...  "
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ],
      "id": "c730bb3b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56149fc7"
      },
      "outputs": [],
      "source": [
        "# 인코더의 입력, 디코더의 입력과 레이블을 각각 다시 Numpy 타입으로 저장\n",
        "encoder_input = np.array(data['text']) # 인코더의 입력\n",
        "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
        "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
      ],
      "id": "56149fc7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41199bb8"
      },
      "outputs": [],
      "source": [
        "# encoder_input과 크기와 형태가 같은 순서가 섞인 정수 시퀀스를 만들기\n",
        "indices = np.arange(encoder_input.shape[0])\n",
        "np.random.shuffle(indices)"
      ],
      "id": "41199bb8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "288da0bb"
      },
      "outputs": [],
      "source": [
        "# shuffle된 indices 시퀀스를 이용해 잘 섞인 샘플 만들기\n",
        "encoder_input = encoder_input[indices]\n",
        "decoder_input = decoder_input[indices]\n",
        "decoder_target = decoder_target[indices]\n",
        "\n",
        "# 섞인 데이터를 8:2의 비율로 훈련 데이터와 테스트 데이터로 분리\n",
        "# 텍스트 데이터 갯수 정하기\n",
        "n_of_val = int(len(encoder_input)*0.2)\n",
        "\n",
        "# 데이터 나누기\n",
        "encoder_input_train = encoder_input[:-n_of_val]\n",
        "decoder_input_train = decoder_input[:-n_of_val]\n",
        "decoder_target_train = decoder_target[:-n_of_val]\n",
        "\n",
        "encoder_input_test = encoder_input[-n_of_val:]\n",
        "decoder_input_test = decoder_input[-n_of_val:]\n",
        "decoder_target_test = decoder_target[-n_of_val:]"
      ],
      "id": "288da0bb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07a17b17"
      },
      "outputs": [],
      "source": [
        "# Keras의 토크나이저를 사용해서 입력된 훈련 데이터로부터 단어 집합을 만들기\n",
        "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
        "src_tokenizer.fit_on_texts(encoder_input_train) # 리스트를 인자로 받고 숫자정보를 매핑"
      ],
      "id": "07a17b17"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9501f41f",
        "outputId": "42c34412-48bf-4206-ac96-b617ac1721d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "단어 집합(vocabulary)의 크기 : 69683\n",
            "등장 빈도가 6번 이하인 희귀 단어의 수: 47572\n",
            "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 22111\n",
            "단어 집합에서 희귀 단어의 비율: 68.26916177546892\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.504797170973492\n"
          ]
        }
      ],
      "source": [
        "# 등장 빈도수가 7회 미만인 단어들이 이 데이터에서 얼만큼의 비중을 차지하는지 확인\n",
        "threshold = 7\n",
        "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
        "\n",
        "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
        "for key, value in src_tokenizer.word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if(value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
        "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ],
      "id": "9501f41f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1b5bf07b"
      },
      "outputs": [],
      "source": [
        "src_vocab = 20000\n",
        "src_tokenizer2 = Tokenizer(num_words=src_vocab)\n",
        "src_tokenizer2.fit_on_texts(encoder_input_train) # 단어 집합 재생성"
      ],
      "id": "1b5bf07b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3c788e00",
        "outputId": "441fc3dc-ab23-4537-f7da-e897dcfc7aa6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "단어 집합 : 69684\n"
          ]
        }
      ],
      "source": [
        "src_vocab_size = len(src_tokenizer2.word_index) + 1 # 패딩을 고려하여 +1\n",
        "print('단어 집합 :',src_vocab_size)"
      ],
      "id": "3c788e00"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c486e490"
      },
      "outputs": [],
      "source": [
        "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
        "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train)\n",
        "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)"
      ],
      "id": "c486e490"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19f83458"
      },
      "outputs": [],
      "source": [
        "tar_tokenizer = Tokenizer()\n",
        "tar_tokenizer.fit_on_texts(decoder_input_train)"
      ],
      "id": "19f83458"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6da45521",
        "outputId": "feb99b87-cea7-48f0-86bf-882ba36f9edd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "단어 집합(vocabulary)의 크기 : 29925\n",
            "등장 빈도가 5번 이하인 희귀 단어의 수: 19481\n",
            "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 10444\n",
            "단어 집합에서 희귀 단어의 비율: 65.09941520467837\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 4.601962545354366\n"
          ]
        }
      ],
      "source": [
        "threshold = 6\n",
        "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
        "\n",
        "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
        "for key, value in tar_tokenizer.word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if(value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
        "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ],
      "id": "6da45521"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6c7e1f6e"
      },
      "outputs": [],
      "source": [
        "tar_vocab = 10000\n",
        "tar_tokenizer2 = Tokenizer(num_words=tar_vocab)\n",
        "tar_tokenizer2.fit_on_texts(decoder_input_train)\n",
        "tar_tokenizer2.fit_on_texts(decoder_target_train)"
      ],
      "id": "6c7e1f6e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2661ec9c",
        "outputId": "93378330-c759-4b75-8539-eec7df630bb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "단어 집합 : 29927\n"
          ]
        }
      ],
      "source": [
        "tar_vocab_size = len(tar_tokenizer2.word_index) + 1 # 패딩을 고려하여 +1\n",
        "print('단어 집합 :',tar_vocab_size)"
      ],
      "id": "2661ec9c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fa8f56d4"
      },
      "outputs": [],
      "source": [
        "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
        "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train)\n",
        "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
        "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
        "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)"
      ],
      "id": "fa8f56d4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3aa8ee2",
        "outputId": "fa09bea6-6484-437b-8dc1-f9555fdee253"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "삭제할 훈련 데이터의 개수 : 0\n",
            "삭제할 테스트 데이터의 개수 : 0\n",
            "훈련 데이터의 개수 : 78609\n",
            "훈련 레이블의 개수 : 78609\n",
            "테스트 데이터의 개수 : 19652\n",
            "테스트 레이블의 개수 : 19652\n"
          ]
        }
      ],
      "source": [
        "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
        "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
        "\n",
        "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
        "print('삭제할 테스트 데이터의 개수 :', len(drop_test))\n",
        "\n",
        "encoder_input_train = [sentence for index, sentence in enumerate(encoder_input_train) if index not in drop_train]\n",
        "decoder_input_train = [sentence for index, sentence in enumerate(decoder_input_train) if index not in drop_train]\n",
        "decoder_target_train = [sentence for index, sentence in enumerate(decoder_target_train) if index not in drop_train]\n",
        "\n",
        "encoder_input_test = [sentence for index, sentence in enumerate(encoder_input_test) if index not in drop_test]\n",
        "decoder_input_test = [sentence for index, sentence in enumerate(decoder_input_test) if index not in drop_test]\n",
        "decoder_target_test = [sentence for index, sentence in enumerate(decoder_target_test) if index not in drop_test]\n",
        "\n",
        "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
        "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
        "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
        "print('테스트 레이블의 개수 :', len(decoder_input_test))"
      ],
      "id": "d3aa8ee2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52eabf05"
      },
      "outputs": [],
      "source": [
        "text_max_len = 60\n",
        "head_max_len = 16\n",
        "\n",
        "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
        "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
        "decoder_input_train = pad_sequences(decoder_input_train, maxlen=head_max_len, padding='post')\n",
        "decoder_target_train = pad_sequences(decoder_target_train, maxlen=head_max_len, padding='post')\n",
        "decoder_input_test = pad_sequences(decoder_input_test, maxlen=head_max_len, padding='post')\n",
        "decoder_target_test = pad_sequences(decoder_target_test, maxlen=head_max_len, padding='post')"
      ],
      "id": "52eabf05"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0e0fc2d"
      },
      "outputs": [],
      "source": [
        "from urllib.request import urlretrieve, urlopen\n",
        "import gzip\n",
        "import zipfile"
      ],
      "id": "d0e0fc2d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8f227b4"
      },
      "outputs": [],
      "source": [
        "embedding_dict = dict()\n",
        "\n",
        "f = open('glove.6B.100d.txt', encoding=\"utf8\")\n",
        "\n",
        "for line in f:\n",
        "    word_vector = line.split()\n",
        "    word = word_vector[0]\n",
        "\n",
        "    # 100개의 값을 가지는 array로 변환\n",
        "    word_vector_arr = np.asarray(word_vector[1:], dtype='float32')\n",
        "    embedding_dict[word] = word_vector_arr\n",
        "f.close()"
      ],
      "id": "e8f227b4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7edc09a8"
      },
      "outputs": [],
      "source": [
        "embedding_matrix_src = np.zeros((src_vocab_size, 100))\n",
        "\n",
        "for word, index in src_tokenizer.word_index.items():\n",
        "    # 단어와 맵핑되는 사전 훈련된 임베딩 벡터값\n",
        "    vector_value = embedding_dict.get(word)\n",
        "    if vector_value is not None:\n",
        "        embedding_matrix_src[index] = vector_value"
      ],
      "id": "7edc09a8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36b9af29"
      },
      "outputs": [],
      "source": [
        "embedding_matrix_tar = np.zeros((tar_vocab_size, 100))\n",
        "\n",
        "for word, index in tar_tokenizer.word_index.items():\n",
        "    # 단어와 맵핑되는 사전 훈련된 임베딩 벡터값\n",
        "    vector_value = embedding_dict.get(word)\n",
        "    if vector_value is not None:\n",
        "        embedding_matrix_tar[index] = vector_value"
      ],
      "id": "36b9af29"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fe373433"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# 인코더 설계 시작\n",
        "output_dim = 100\n",
        "hidden_size = 256\n",
        "\n",
        "# 인코더\n",
        "encoder_inputs = Input(shape=(text_max_len,))\n",
        "\n",
        "# 인코더의 임베딩 층\n",
        "enc_emb = Embedding(src_vocab_size, output_dim, weights=[embedding_matrix_src], input_length=text_max_len, trainable=False)(encoder_inputs)\n",
        "\n",
        "# 인코더의 LSTM 1\n",
        "# encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
        "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "# 인코더의 LSTM 2\n",
        "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "# 인코더의 LSTM 3\n",
        "encoder_lstm3 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm3(encoder_output2)"
      ],
      "id": "fe373433"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08c2f776"
      },
      "outputs": [],
      "source": [
        "# 디코더 설계\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "# 디코더의 임베딩 층\n",
        "dec_emb = Embedding(tar_vocab_size, output_dim, weights=[embedding_matrix_tar], input_length=head_max_len, trainable=False)(decoder_inputs)\n",
        "\n",
        "# 디코더의 LSTM\n",
        "# decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
        "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])"
      ],
      "id": "08c2f776"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9b432df"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import AdditiveAttention\n",
        "\n",
        "# 어텐션 층(어텐션 함수)\n",
        "attn_layer = AdditiveAttention(name='attention_layer')\n",
        "\n",
        "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
        "attn_out = attn_layer([decoder_outputs, encoder_outputs])\n",
        "\n",
        "\n",
        "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "# 디코더의 출력층\n",
        "decoder_softmax_layer = Dense(tar_vocab_size, activation='softmax')\n",
        "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
        "\n",
        "# 모델 정의\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
        "model.summary()"
      ],
      "id": "c9b432df"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ce3757d3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# NaN이나 Inf가 있는지 확인\n",
        "print(np.isnan(encoder_input_train).any(), np.isnan(decoder_input_train).any())\n",
        "print(np.isinf(encoder_input_train).any(), np.isinf(decoder_input_train).any())"
      ],
      "id": "ce3757d3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52744e52"
      },
      "outputs": [],
      "source": [
        "print(np.isnan(embedding_matrix_src).any())  # True가 출력되면 NaN이 존재\n",
        "print(np.isnan(embedding_matrix_tar).any())  # True가 출력되면 NaN이 존재"
      ],
      "id": "52744e52"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26c3c277"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model.compile(optimizer=RMSprop(learning_rate=0.001), loss='sparse_categorical_crossentropy')\n",
        "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
        "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
        "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
        "          batch_size=512, callbacks=[es], epochs=50)"
      ],
      "id": "26c3c277"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b470611d"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='val')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "b470611d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# word2vec + transformer\n"
      ],
      "metadata": {
        "id": "4c3umFpc6OLo"
      },
      "id": "4c3umFpc6OLo"
    },
    {
      "cell_type": "markdown",
      "id": "9ce8862a",
      "metadata": {
        "id": "9ce8862a"
      },
      "source": [
        "## 1. 데이터 준비 및 전처리"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQikhVLvp6jO",
        "outputId": "1b85a6e3-f341-4e6c-f665-2f772c3984de"
      },
      "id": "PQikhVLvp6jO",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a71f35b2",
      "metadata": {
        "id": "a71f35b2"
      },
      "outputs": [],
      "source": [
        "# import nltk\n",
        "# nltk.download('stopwords')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "from bs4 import BeautifulSoup\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import urllib.request\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "70802f76",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "70802f76",
        "outputId": "e7e88b04-3efe-46e8-d1ac-5fc9e09a41c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 summary  \\\n",
              "0      upgrad learner switches to career in ml al wit...   \n",
              "1      delhi techie wins free food from swiggy for on...   \n",
              "2      new zealand end rohit sharma led india match w...   \n",
              "3      aegon life iterm insurance plan helps customer...   \n",
              "4      have known hirani for yrs what if metoo claims...   \n",
              "...                                                  ...   \n",
              "16776  bsf jawan arrested for spying police say he wa...   \n",
              "16777  kolkata bagree market fire completely controll...   \n",
              "16778  sc summons delhi bjp chief for breaking lock o...   \n",
              "16779  pakistan pm visits saudi arabia for bailout ta...   \n",
              "16780  chairman wealth surges billion after buyout re...   \n",
              "\n",
              "                                                    text  \n",
              "0      saurav kant alumnus upgrad iiit pg program mac...  \n",
              "1      kunal shah credit card bill payment platform c...  \n",
              "2      new zealand defeated india wickets fourth odi ...  \n",
              "3      aegon life iterm insurance plan customers enjo...  \n",
              "4      speaking sexual harassment allegations rajkuma...  \n",
              "...                                                  ...  \n",
              "16776  bsf jawan alleged honey trapped pakistan isi a...  \n",
              "16777  senior fire department official said fire erup...  \n",
              "16778  supreme court issued contempt notice delhi bjp...  \n",
              "16779  pakistan prime minister imran khan visiting sa...  \n",
              "16780  shares surged monday boosting wealth chairman ...  \n",
              "\n",
              "[16781 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e67d085a-386e-46f3-adb8-1d3d6fcd321a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>summary</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>upgrad learner switches to career in ml al wit...</td>\n",
              "      <td>saurav kant alumnus upgrad iiit pg program mac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>delhi techie wins free food from swiggy for on...</td>\n",
              "      <td>kunal shah credit card bill payment platform c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>new zealand end rohit sharma led india match w...</td>\n",
              "      <td>new zealand defeated india wickets fourth odi ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>aegon life iterm insurance plan helps customer...</td>\n",
              "      <td>aegon life iterm insurance plan customers enjo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>have known hirani for yrs what if metoo claims...</td>\n",
              "      <td>speaking sexual harassment allegations rajkuma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16776</th>\n",
              "      <td>bsf jawan arrested for spying police say he wa...</td>\n",
              "      <td>bsf jawan alleged honey trapped pakistan isi a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16777</th>\n",
              "      <td>kolkata bagree market fire completely controll...</td>\n",
              "      <td>senior fire department official said fire erup...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16778</th>\n",
              "      <td>sc summons delhi bjp chief for breaking lock o...</td>\n",
              "      <td>supreme court issued contempt notice delhi bjp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16779</th>\n",
              "      <td>pakistan pm visits saudi arabia for bailout ta...</td>\n",
              "      <td>pakistan prime minister imran khan visiting sa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16780</th>\n",
              "      <td>chairman wealth surges billion after buyout re...</td>\n",
              "      <td>shares surged monday boosting wealth chairman ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16781 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e67d085a-386e-46f3-adb8-1d3d6fcd321a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e67d085a-386e-46f3-adb8-1d3d6fcd321a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e67d085a-386e-46f3-adb8-1d3d6fcd321a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2dc5b676-b495-4647-9ec2-37b85f200edb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2dc5b676-b495-4647-9ec2-37b85f200edb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2dc5b676-b495-4647-9ec2-37b85f200edb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_47a3af9c-e88b-400e-b515-5d9b835ca0f0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_47a3af9c-e88b-400e-b515-5d9b835ca0f0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 16781,\n  \"fields\": [\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16772,\n        \"samples\": [\n          \"kerala to announce cr health insurance plan in budget\",\n          \"canada trying to end billion arms deal with saudi pm trudeau\",\n          \"govt may pay farmers cash instead of subsidies reports\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16781,\n        \"samples\": [\n          \"harikumar deputy superintendent police kerala neyyattinkara evading arrest accused causing year old electrician death found hanging home tuesday harikumar allegedly pushed man front speeding vehicle altercation parked cars november run since\",\n          \"citizenship bill makes minority immigrants afghanistan bangladesh pakistan entered india december eligible indian citizenship passed lok sabha bill passed amid protests assam bill congress tmc mps staged walk discussion bill\",\n          \"jammu kashmir governor satya pal malik said talked ipl chairman rajeev shukla forming ipl team state plan ipl team plans cricket football team focusing ipl team malik said plan\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/sample_data/news_data.csv\")\n",
        "# df.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "df.rename(columns = {'headlines' : 'summary'}, inplace=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f97b9de8",
      "metadata": {
        "id": "f97b9de8"
      },
      "outputs": [],
      "source": [
        "# 훈련 데이터와 테스트 데이터로 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['summary'], test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3d1e582e",
      "metadata": {
        "id": "3d1e582e"
      },
      "outputs": [],
      "source": [
        "# 텍스트를 시퀀스로 변환\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "y_train_seq = tokenizer.texts_to_sequences(y_train)\n",
        "y_test_seq = tokenizer.texts_to_sequences(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f5b91d46",
      "metadata": {
        "id": "f5b91d46"
      },
      "outputs": [],
      "source": [
        "# 패딩 처리\n",
        "\n",
        "max_seq_length = 100  # 최대 시퀀스 길이\n",
        "X_train_padded = pad_sequences(X_train_seq, maxlen=max_seq_length, padding='post')\n",
        "X_test_padded = pad_sequences(X_test_seq, maxlen=max_seq_length, padding='post')\n",
        "y_train_padded = pad_sequences(y_train_seq, maxlen=max_seq_length, padding='post')\n",
        "y_test_padded = pad_sequences(y_test_seq, maxlen=max_seq_length, padding='post')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da6b268f",
      "metadata": {
        "id": "da6b268f"
      },
      "source": [
        "## 2. Word2Vec 임베딩"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "fa12f53f",
      "metadata": {
        "id": "fa12f53f"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "5584f7b0",
      "metadata": {
        "id": "5584f7b0"
      },
      "outputs": [],
      "source": [
        "# Word2Vec 모델 학습\n",
        "sentences = [text.split() for text in X_train]\n",
        "word2vec_model = gensim.models.Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "d1d86cf1",
      "metadata": {
        "id": "d1d86cf1"
      },
      "outputs": [],
      "source": [
        "# 임베딩 매트릭스 생성\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_dim = 100\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in word2vec_model.wv:\n",
        "        embedding_matrix[i] = word2vec_model.wv[word]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "990d96a3",
      "metadata": {
        "id": "990d96a3"
      },
      "outputs": [],
      "source": [
        "# 임베딩 레이어 생성\n",
        "embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_seq_length, trainable=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7749a1b",
      "metadata": {
        "id": "d7749a1b"
      },
      "source": [
        "## 3. 트랜스포머 모델 설계"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "6c6d1307",
      "metadata": {
        "id": "6c6d1307"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling1D, TimeDistributed\n",
        "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dropout, Add"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "fd032057",
      "metadata": {
        "id": "fd032057"
      },
      "outputs": [],
      "source": [
        "# 트랜스포머 블록 정의\n",
        "def transformer_block(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    attention_output = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)\n",
        "    attention_output = Dropout(dropout)(attention_output)\n",
        "    attention_output = LayerNormalization(epsilon=1e-6)(attention_output + inputs)\n",
        "\n",
        "    ff_output = Dense(ff_dim, activation=\"relu\")(attention_output)\n",
        "    ff_output = Dropout(dropout)(ff_output)\n",
        "    ff_output = Dense(inputs.shape[-1])(ff_output)\n",
        "    ff_output = Add()([ff_output, attention_output])\n",
        "\n",
        "    return LayerNormalization(epsilon=1e-6)(ff_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "46d07ae1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "id": "46d07ae1",
        "outputId": "a3ddf63e-8f55-46b8-b5f6-dc6fdc5eb0d2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │      \u001b[38;5;34m3,141,900\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │        \u001b[38;5;34m206,436\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                           │                        │                │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │            \u001b[38;5;34m200\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │         \u001b[38;5;34m12,928\u001b[0m │ layer_normalization_4… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │         \u001b[38;5;34m12,900\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
              "│                           │                        │                │ layer_normalization_4… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │            \u001b[38;5;34m200\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_5… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ time_distributed_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m31419\u001b[0m)     │      \u001b[38;5;34m3,173,319\u001b[0m │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)         │                        │                │                        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,141,900</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">206,436</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                           │                        │                │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">12,928</span> │ layer_normalization_4… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">12,900</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
              "│                           │                        │                │ layer_normalization_4… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_5… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ time_distributed_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31419</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,173,319</span> │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)         │                        │                │                        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,547,883\u001b[0m (24.98 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,547,883</span> (24.98 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,405,983\u001b[0m (12.99 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,405,983</span> (12.99 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,141,900\u001b[0m (11.99 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,141,900</span> (11.99 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 모델 정의\n",
        "inputs = Input(shape=(max_seq_length,))\n",
        "x = embedding_layer(inputs)\n",
        "x = transformer_block(x, head_size=128, num_heads=4, ff_dim=128, dropout=0.1)\n",
        "x = Dropout(0.1)(x)\n",
        "outputs = TimeDistributed(Dense(vocab_size, activation=\"softmax\"))(x)  # 각 시퀀스 타임스텝마다 출력\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "740b0528",
      "metadata": {
        "id": "740b0528"
      },
      "source": [
        "3# 4. 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "39f21fcd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39f21fcd",
        "outputId": "f01df8ff-2cd0-4a76-8c69-b2438086f3c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 1s/step - accuracy: 0.8431 - loss: 6.5946 - val_accuracy: 0.9273 - val_loss: 0.9005\n",
            "Epoch 2/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 385ms/step - accuracy: 0.9275 - loss: 0.8881 - val_accuracy: 0.9273 - val_loss: 0.8774\n",
            "Epoch 3/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 378ms/step - accuracy: 0.9277 - loss: 0.8513 - val_accuracy: 0.9273 - val_loss: 0.8118\n",
            "Epoch 4/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 379ms/step - accuracy: 0.9275 - loss: 0.8033 - val_accuracy: 0.9273 - val_loss: 0.7976\n",
            "Epoch 5/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 381ms/step - accuracy: 0.9274 - loss: 0.7875 - val_accuracy: 0.9273 - val_loss: 0.7823\n",
            "Epoch 6/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 379ms/step - accuracy: 0.9276 - loss: 0.7677 - val_accuracy: 0.9273 - val_loss: 0.7695\n",
            "Epoch 7/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 380ms/step - accuracy: 0.9275 - loss: 0.7521 - val_accuracy: 0.9273 - val_loss: 0.7612\n",
            "Epoch 8/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 381ms/step - accuracy: 0.9278 - loss: 0.7369 - val_accuracy: 0.9273 - val_loss: 0.7538\n",
            "Epoch 9/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 380ms/step - accuracy: 0.9276 - loss: 0.7258 - val_accuracy: 0.9273 - val_loss: 0.7483\n",
            "Epoch 10/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 380ms/step - accuracy: 0.9278 - loss: 0.7128 - val_accuracy: 0.9273 - val_loss: 0.7436\n",
            "Epoch 11/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 379ms/step - accuracy: 0.9276 - loss: 0.7055 - val_accuracy: 0.9273 - val_loss: 0.7396\n",
            "Epoch 12/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 379ms/step - accuracy: 0.9276 - loss: 0.6978 - val_accuracy: 0.9273 - val_loss: 0.7376\n",
            "Epoch 13/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 381ms/step - accuracy: 0.9277 - loss: 0.6885 - val_accuracy: 0.9273 - val_loss: 0.7358\n",
            "Epoch 14/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 381ms/step - accuracy: 0.9276 - loss: 0.6809 - val_accuracy: 0.9273 - val_loss: 0.7338\n",
            "Epoch 15/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 380ms/step - accuracy: 0.9276 - loss: 0.6747 - val_accuracy: 0.9273 - val_loss: 0.7322\n",
            "Epoch 16/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 379ms/step - accuracy: 0.9274 - loss: 0.6698 - val_accuracy: 0.9273 - val_loss: 0.7322\n",
            "Epoch 17/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 382ms/step - accuracy: 0.9278 - loss: 0.6611 - val_accuracy: 0.9273 - val_loss: 0.7310\n",
            "Epoch 18/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 380ms/step - accuracy: 0.9276 - loss: 0.6550 - val_accuracy: 0.9273 - val_loss: 0.7309\n",
            "Epoch 19/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 379ms/step - accuracy: 0.9275 - loss: 0.6512 - val_accuracy: 0.9273 - val_loss: 0.7305\n",
            "Epoch 20/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 380ms/step - accuracy: 0.9276 - loss: 0.6437 - val_accuracy: 0.9273 - val_loss: 0.7308\n",
            "Epoch 21/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 381ms/step - accuracy: 0.9279 - loss: 0.6361 - val_accuracy: 0.9273 - val_loss: 0.7309\n",
            "Epoch 22/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 380ms/step - accuracy: 0.9275 - loss: 0.6356 - val_accuracy: 0.9273 - val_loss: 0.7313\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# 조기 종료 콜백 설정\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# 모델 학습\n",
        "history = model.fit(X_train_padded, y_train_padded, validation_split=0.2, epochs=50, batch_size=128, callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ca94730",
      "metadata": {
        "id": "4ca94730"
      },
      "source": [
        "## 5. 학습 결과"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "353c34cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "353c34cb",
        "outputId": "b903b5ec-7b0b-421f-aada-bf2c47cb72a0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 학습 결과 시각화\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05e9f985",
      "metadata": {
        "id": "05e9f985"
      },
      "source": [
        "## 6. 예측 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "e10e24f4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e10e24f4",
        "outputId": "fb06c068-7a33-44a0-ac7f-53773ba35afd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 158ms/step - accuracy: 0.9287 - loss: 0.7106\n",
            "Test Loss: 0.7079\n",
            "Test Accuracy: 0.9290\n"
          ]
        }
      ],
      "source": [
        "# 모델 평가\n",
        "loss, accuracy = model.evaluate(X_test_padded, y_test_padded)\n",
        "print(f'Test Loss: {loss:.4f}')\n",
        "print(f'Test Accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_generator(X_test_padded, batch_size):\n",
        "    num_samples = X_test_padded.shape[0]\n",
        "    while True:\n",
        "        for offset in range(0, num_samples, batch_size):\n",
        "            batch_data = X_test_padded[offset:offset + batch_size]\n",
        "            yield (batch_data,)  # Yield a tuple containing the input data\n",
        "\n",
        "# 예측 수행\n",
        "batch_size = 32  # Adjust this value based on your available memory\n",
        "predictions = model.predict(data_generator(X_test_padded, batch_size))\n",
        "\n",
        "# 실제 레이블과 예측된 레이블 비교\n",
        "for i in range(5):  # 상위 5개 샘플만 출력\n",
        "    # 예측된 시퀀스 가져오기\n",
        "    predicted_sequence = predictions[i].argmax(axis=-1)\n",
        "\n",
        "    # 실제 레이블 시퀀스 가져오기\n",
        "    actual_sequence = y_test_padded[i]\n",
        "\n",
        "    # 패딩 제거\n",
        "    predicted_sequence = [token for token in predicted_sequence if token != 0]\n",
        "    actual_sequence = [token for token in actual_sequence if token != 0]\n",
        "\n",
        "    # 텍스트로 변환\n",
        "    predicted_text = tokenizer.sequences_to_texts([predicted_sequence])[0]\n",
        "    actual_text = tokenizer.sequences_to_texts([actual_sequence])[0]\n",
        "\n",
        "    # 출력\n",
        "    print(f\"Sample {i+1}\")\n",
        "    print(f\"Predicted: {predicted_text}\")\n",
        "    print(f\"Actual: {actual_text}\")\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KrQfMUci4aMd",
        "outputId": "93c9978b-c396-4a5c-ff4d-6f4727d2bc5e"
      },
      "id": "KrQfMUci4aMd",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-44-19c696aed8e9>\", line 10, in <cell line: 10>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 508, in predict\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 208, in one_step_on_data_distributed\n\nOut of memory while trying to allocate 402163200 bytes.\n\t [[{{node StatefulPartitionedCall}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_one_step_on_data_distributed_49387]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-19c696aed8e9>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 예측 수행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m  \u001b[0;31m# Adjust this value based on your available memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 실제 레이블과 예측된 레이블 비교\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-44-19c696aed8e9>\", line 10, in <cell line: 10>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 508, in predict\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 208, in one_step_on_data_distributed\n\nOut of memory while trying to allocate 402163200 bytes.\n\t [[{{node StatefulPartitionedCall}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_one_step_on_data_distributed_49387]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEQrM0KC2w27",
        "outputId": "6eac5ebf-11f4-4010-cc57-0f1a16492256"
      },
      "id": "bEQrM0KC2w27",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "metadata": {
        "id": "SG9uJf2R2OAo"
      },
      "id": "SG9uJf2R2OAo",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리 함수\n",
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower() # 텍스트 소문자화\n",
        "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
        "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
        "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
        "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
        "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
        "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
        "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
        "\n",
        "    tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
        "\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "luD3p6o62P8O"
      },
      "id": "luD3p6o62P8O",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "bd296955",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd296955",
        "outputId": "9133680f-59b4-4abd-eb96-af538d946407"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Predicted Summary: \n"
          ]
        }
      ],
      "source": [
        "# 샘플 예측\n",
        "sample_text = \"Example news content to summarize\"\n",
        "\n",
        "sample_seq = tokenizer.texts_to_sequences([preprocess_sentence(sample_text)])\n",
        "\n",
        "max_seq_length = 100  # 최대 시퀀스 길이\n",
        "sample_padded = pad_sequences(sample_seq, maxlen=max_seq_length, padding='post')\n",
        "\n",
        "predicted_summary = model.predict(sample_padded)\n",
        "predicted_summary = tokenizer.sequences_to_texts(predicted_summary.argmax(axis=-1))\n",
        "print(\"Predicted Summary:\", \" \".join(predicted_summary))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 회고"
      ],
      "metadata": {
        "id": "NiZtlTAx8W2E"
      },
      "id": "NiZtlTAx8W2E"
    },
    {
      "cell_type": "markdown",
      "source": [
        "이유진 : 임베딩 층을 바꿔보는것도 쉽지 않았다. 임베딩 층을 새로 적용하니 모델 결과 예측하는 것도 바꾸어야 하는데 쉽지 않아 아쉬웠다. 하지만 토크나이징, 임베딩, LTSM, transformer 모델에 대해 조금은 더 이해할 수 있었던것 같다. 시간이 없어 플러터를 구현하지 못한부분도 너무 아쉽다."
      ],
      "metadata": {
        "id": "iLXlSecO8ZH-"
      },
      "id": "iLXlSecO8ZH-"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "4c3umFpc6OLo"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}